{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42018ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /home/manas/miniconda3/envs/pytorch/lib/python3.11/site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4449238f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader , Dataset\n",
    "#from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed4c0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.5.1+cu121\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: /home/manas/miniconda3/envs/pytorch/lib/python3.11/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
      "Required-by: torchaudio, torchvision\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4bdbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93261c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))  # only if CUDA is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b30e948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4537</td>\n",
       "      <td>92.229316</td>\n",
       "      <td>64.012769</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>4677</td>\n",
       "      <td>76.004525</td>\n",
       "      <td>0.657536</td>\n",
       "      <td>273.085</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>1.440796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2872</td>\n",
       "      <td>74.691881</td>\n",
       "      <td>51.400454</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>3015</td>\n",
       "      <td>60.471018</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>208.317</td>\n",
       "      <td>0.831658</td>\n",
       "      <td>1.453137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3048</td>\n",
       "      <td>76.293164</td>\n",
       "      <td>52.043491</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>3132</td>\n",
       "      <td>62.296341</td>\n",
       "      <td>0.759153</td>\n",
       "      <td>210.012</td>\n",
       "      <td>0.868434</td>\n",
       "      <td>1.465950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3073</td>\n",
       "      <td>77.033628</td>\n",
       "      <td>51.928487</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>3157</td>\n",
       "      <td>62.551300</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>210.657</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>1.483456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3693</td>\n",
       "      <td>85.124785</td>\n",
       "      <td>56.374021</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>3802</td>\n",
       "      <td>68.571668</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>230.332</td>\n",
       "      <td>0.874743</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "0   1  4537        92.229316        64.012769      0.719916        4677   \n",
       "1   2  2872        74.691881        51.400454      0.725553        3015   \n",
       "2   3  3048        76.293164        52.043491      0.731211        3132   \n",
       "3   4  3073        77.033628        51.928487      0.738639        3157   \n",
       "4   5  3693        85.124785        56.374021      0.749282        3802   \n",
       "\n",
       "   EquivDiameter    Extent  Perimeter  Roundness  AspectRation  Class  \n",
       "0      76.004525  0.657536    273.085   0.764510      1.440796      1  \n",
       "1      60.471018  0.713009    208.317   0.831658      1.453137      1  \n",
       "2      62.296341  0.759153    210.012   0.868434      1.465950      1  \n",
       "3      62.551300  0.783529    210.657   0.870203      1.483456      1  \n",
       "4      68.571668  0.769375    230.332   0.874743      1.510000      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('/home/manas/Downloads/riceClassification.csv')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c9b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a05288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4537</td>\n",
       "      <td>92.229316</td>\n",
       "      <td>64.012769</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>4677</td>\n",
       "      <td>76.004525</td>\n",
       "      <td>0.657536</td>\n",
       "      <td>273.085</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>1.440796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2872</td>\n",
       "      <td>74.691881</td>\n",
       "      <td>51.400454</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>3015</td>\n",
       "      <td>60.471018</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>208.317</td>\n",
       "      <td>0.831658</td>\n",
       "      <td>1.453137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3048</td>\n",
       "      <td>76.293164</td>\n",
       "      <td>52.043491</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>3132</td>\n",
       "      <td>62.296341</td>\n",
       "      <td>0.759153</td>\n",
       "      <td>210.012</td>\n",
       "      <td>0.868434</td>\n",
       "      <td>1.465950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3073</td>\n",
       "      <td>77.033628</td>\n",
       "      <td>51.928487</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>3157</td>\n",
       "      <td>62.551300</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>210.657</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>1.483456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3693</td>\n",
       "      <td>85.124785</td>\n",
       "      <td>56.374021</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>3802</td>\n",
       "      <td>68.571668</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>230.332</td>\n",
       "      <td>0.874743</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>18181</td>\n",
       "      <td>5853</td>\n",
       "      <td>148.624571</td>\n",
       "      <td>51.029281</td>\n",
       "      <td>0.939210</td>\n",
       "      <td>6008</td>\n",
       "      <td>86.326537</td>\n",
       "      <td>0.498594</td>\n",
       "      <td>332.960</td>\n",
       "      <td>0.663444</td>\n",
       "      <td>2.912535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>18182</td>\n",
       "      <td>7585</td>\n",
       "      <td>169.593996</td>\n",
       "      <td>58.141659</td>\n",
       "      <td>0.939398</td>\n",
       "      <td>7806</td>\n",
       "      <td>98.272692</td>\n",
       "      <td>0.647461</td>\n",
       "      <td>385.506</td>\n",
       "      <td>0.641362</td>\n",
       "      <td>2.916910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18182</th>\n",
       "      <td>18183</td>\n",
       "      <td>6365</td>\n",
       "      <td>154.777085</td>\n",
       "      <td>52.908085</td>\n",
       "      <td>0.939760</td>\n",
       "      <td>6531</td>\n",
       "      <td>90.023162</td>\n",
       "      <td>0.561287</td>\n",
       "      <td>342.253</td>\n",
       "      <td>0.682832</td>\n",
       "      <td>2.925396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18183</th>\n",
       "      <td>18184</td>\n",
       "      <td>5960</td>\n",
       "      <td>151.397924</td>\n",
       "      <td>51.474600</td>\n",
       "      <td>0.940427</td>\n",
       "      <td>6189</td>\n",
       "      <td>87.112041</td>\n",
       "      <td>0.492399</td>\n",
       "      <td>343.371</td>\n",
       "      <td>0.635227</td>\n",
       "      <td>2.941216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18184</th>\n",
       "      <td>18185</td>\n",
       "      <td>6134</td>\n",
       "      <td>153.081981</td>\n",
       "      <td>51.590606</td>\n",
       "      <td>0.941500</td>\n",
       "      <td>6283</td>\n",
       "      <td>88.374495</td>\n",
       "      <td>0.489975</td>\n",
       "      <td>338.613</td>\n",
       "      <td>0.672274</td>\n",
       "      <td>2.967245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18185 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Area  MajorAxisLength  MinorAxisLength  Eccentricity  \\\n",
       "0          1  4537        92.229316        64.012769      0.719916   \n",
       "1          2  2872        74.691881        51.400454      0.725553   \n",
       "2          3  3048        76.293164        52.043491      0.731211   \n",
       "3          4  3073        77.033628        51.928487      0.738639   \n",
       "4          5  3693        85.124785        56.374021      0.749282   \n",
       "...      ...   ...              ...              ...           ...   \n",
       "18180  18181  5853       148.624571        51.029281      0.939210   \n",
       "18181  18182  7585       169.593996        58.141659      0.939398   \n",
       "18182  18183  6365       154.777085        52.908085      0.939760   \n",
       "18183  18184  5960       151.397924        51.474600      0.940427   \n",
       "18184  18185  6134       153.081981        51.590606      0.941500   \n",
       "\n",
       "       ConvexArea  EquivDiameter    Extent  Perimeter  Roundness  \\\n",
       "0            4677      76.004525  0.657536    273.085   0.764510   \n",
       "1            3015      60.471018  0.713009    208.317   0.831658   \n",
       "2            3132      62.296341  0.759153    210.012   0.868434   \n",
       "3            3157      62.551300  0.783529    210.657   0.870203   \n",
       "4            3802      68.571668  0.769375    230.332   0.874743   \n",
       "...           ...            ...       ...        ...        ...   \n",
       "18180        6008      86.326537  0.498594    332.960   0.663444   \n",
       "18181        7806      98.272692  0.647461    385.506   0.641362   \n",
       "18182        6531      90.023162  0.561287    342.253   0.682832   \n",
       "18183        6189      87.112041  0.492399    343.371   0.635227   \n",
       "18184        6283      88.374495  0.489975    338.613   0.672274   \n",
       "\n",
       "       AspectRation  Class  \n",
       "0          1.440796      1  \n",
       "1          1.453137      1  \n",
       "2          1.465950      1  \n",
       "3          1.483456      1  \n",
       "4          1.510000      1  \n",
       "...             ...    ...  \n",
       "18180      2.912535      0  \n",
       "18181      2.916910      0  \n",
       "18182      2.925396      0  \n",
       "18183      2.941216      0  \n",
       "18184      2.967245      0  \n",
       "\n",
       "[18185 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e02efc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "375c0308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df['Class'].value_counts()\n",
    "data_df['Class'].value_counts().plot(kind='bar')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfc33efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4537</td>\n",
       "      <td>92.229316</td>\n",
       "      <td>64.012769</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>4677</td>\n",
       "      <td>76.004525</td>\n",
       "      <td>0.657536</td>\n",
       "      <td>273.085</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>1.440796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2872</td>\n",
       "      <td>74.691881</td>\n",
       "      <td>51.400454</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>3015</td>\n",
       "      <td>60.471018</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>208.317</td>\n",
       "      <td>0.831658</td>\n",
       "      <td>1.453137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3048</td>\n",
       "      <td>76.293164</td>\n",
       "      <td>52.043491</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>3132</td>\n",
       "      <td>62.296341</td>\n",
       "      <td>0.759153</td>\n",
       "      <td>210.012</td>\n",
       "      <td>0.868434</td>\n",
       "      <td>1.465950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3073</td>\n",
       "      <td>77.033628</td>\n",
       "      <td>51.928487</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>3157</td>\n",
       "      <td>62.551300</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>210.657</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>1.483456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3693</td>\n",
       "      <td>85.124785</td>\n",
       "      <td>56.374021</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>3802</td>\n",
       "      <td>68.571668</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>230.332</td>\n",
       "      <td>0.874743</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>5853</td>\n",
       "      <td>148.624571</td>\n",
       "      <td>51.029281</td>\n",
       "      <td>0.939210</td>\n",
       "      <td>6008</td>\n",
       "      <td>86.326537</td>\n",
       "      <td>0.498594</td>\n",
       "      <td>332.960</td>\n",
       "      <td>0.663444</td>\n",
       "      <td>2.912535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>7585</td>\n",
       "      <td>169.593996</td>\n",
       "      <td>58.141659</td>\n",
       "      <td>0.939398</td>\n",
       "      <td>7806</td>\n",
       "      <td>98.272692</td>\n",
       "      <td>0.647461</td>\n",
       "      <td>385.506</td>\n",
       "      <td>0.641362</td>\n",
       "      <td>2.916910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18182</th>\n",
       "      <td>6365</td>\n",
       "      <td>154.777085</td>\n",
       "      <td>52.908085</td>\n",
       "      <td>0.939760</td>\n",
       "      <td>6531</td>\n",
       "      <td>90.023162</td>\n",
       "      <td>0.561287</td>\n",
       "      <td>342.253</td>\n",
       "      <td>0.682832</td>\n",
       "      <td>2.925396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18183</th>\n",
       "      <td>5960</td>\n",
       "      <td>151.397924</td>\n",
       "      <td>51.474600</td>\n",
       "      <td>0.940427</td>\n",
       "      <td>6189</td>\n",
       "      <td>87.112041</td>\n",
       "      <td>0.492399</td>\n",
       "      <td>343.371</td>\n",
       "      <td>0.635227</td>\n",
       "      <td>2.941216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18184</th>\n",
       "      <td>6134</td>\n",
       "      <td>153.081981</td>\n",
       "      <td>51.590606</td>\n",
       "      <td>0.941500</td>\n",
       "      <td>6283</td>\n",
       "      <td>88.374495</td>\n",
       "      <td>0.489975</td>\n",
       "      <td>338.613</td>\n",
       "      <td>0.672274</td>\n",
       "      <td>2.967245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18185 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "0      4537        92.229316        64.012769      0.719916        4677   \n",
       "1      2872        74.691881        51.400454      0.725553        3015   \n",
       "2      3048        76.293164        52.043491      0.731211        3132   \n",
       "3      3073        77.033628        51.928487      0.738639        3157   \n",
       "4      3693        85.124785        56.374021      0.749282        3802   \n",
       "...     ...              ...              ...           ...         ...   \n",
       "18180  5853       148.624571        51.029281      0.939210        6008   \n",
       "18181  7585       169.593996        58.141659      0.939398        7806   \n",
       "18182  6365       154.777085        52.908085      0.939760        6531   \n",
       "18183  5960       151.397924        51.474600      0.940427        6189   \n",
       "18184  6134       153.081981        51.590606      0.941500        6283   \n",
       "\n",
       "       EquivDiameter    Extent  Perimeter  Roundness  AspectRation  Class  \n",
       "0          76.004525  0.657536    273.085   0.764510      1.440796      1  \n",
       "1          60.471018  0.713009    208.317   0.831658      1.453137      1  \n",
       "2          62.296341  0.759153    210.012   0.868434      1.465950      1  \n",
       "3          62.551300  0.783529    210.657   0.870203      1.483456      1  \n",
       "4          68.571668  0.769375    230.332   0.874743      1.510000      1  \n",
       "...              ...       ...        ...        ...           ...    ...  \n",
       "18180      86.326537  0.498594    332.960   0.663444      2.912535      0  \n",
       "18181      98.272692  0.647461    385.506   0.641362      2.916910      0  \n",
       "18182      90.023162  0.561287    342.253   0.682832      2.925396      0  \n",
       "18183      87.112041  0.492399    343.371   0.635227      2.941216      0  \n",
       "18184      88.374495  0.489975    338.613   0.672274      2.967245      0  \n",
       "\n",
       "[18185 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.drop(columns=['id'], inplace=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55826883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18185, 11)\n"
     ]
    }
   ],
   "source": [
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60fd6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = data_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d265fbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.444368</td>\n",
       "      <td>0.503404</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.744658</td>\n",
       "      <td>0.424873</td>\n",
       "      <td>0.666610</td>\n",
       "      <td>0.741661</td>\n",
       "      <td>0.537029</td>\n",
       "      <td>0.844997</td>\n",
       "      <td>0.368316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.281293</td>\n",
       "      <td>0.407681</td>\n",
       "      <td>0.622653</td>\n",
       "      <td>0.750489</td>\n",
       "      <td>0.273892</td>\n",
       "      <td>0.530370</td>\n",
       "      <td>0.804230</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>0.919215</td>\n",
       "      <td>0.371471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.298531</td>\n",
       "      <td>0.416421</td>\n",
       "      <td>0.630442</td>\n",
       "      <td>0.756341</td>\n",
       "      <td>0.284520</td>\n",
       "      <td>0.546380</td>\n",
       "      <td>0.856278</td>\n",
       "      <td>0.412994</td>\n",
       "      <td>0.959862</td>\n",
       "      <td>0.374747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.300979</td>\n",
       "      <td>0.420463</td>\n",
       "      <td>0.629049</td>\n",
       "      <td>0.764024</td>\n",
       "      <td>0.286791</td>\n",
       "      <td>0.548616</td>\n",
       "      <td>0.883772</td>\n",
       "      <td>0.414262</td>\n",
       "      <td>0.961818</td>\n",
       "      <td>0.379222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.361704</td>\n",
       "      <td>0.464626</td>\n",
       "      <td>0.682901</td>\n",
       "      <td>0.775033</td>\n",
       "      <td>0.345385</td>\n",
       "      <td>0.601418</td>\n",
       "      <td>0.867808</td>\n",
       "      <td>0.452954</td>\n",
       "      <td>0.966836</td>\n",
       "      <td>0.386007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>0.573262</td>\n",
       "      <td>0.811219</td>\n",
       "      <td>0.618156</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>0.545785</td>\n",
       "      <td>0.757140</td>\n",
       "      <td>0.562384</td>\n",
       "      <td>0.654774</td>\n",
       "      <td>0.733291</td>\n",
       "      <td>0.744543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>0.742899</td>\n",
       "      <td>0.925674</td>\n",
       "      <td>0.704314</td>\n",
       "      <td>0.971683</td>\n",
       "      <td>0.709121</td>\n",
       "      <td>0.861916</td>\n",
       "      <td>0.730296</td>\n",
       "      <td>0.758107</td>\n",
       "      <td>0.708884</td>\n",
       "      <td>0.745661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18182</th>\n",
       "      <td>0.623408</td>\n",
       "      <td>0.844800</td>\n",
       "      <td>0.640916</td>\n",
       "      <td>0.972058</td>\n",
       "      <td>0.593296</td>\n",
       "      <td>0.789562</td>\n",
       "      <td>0.633098</td>\n",
       "      <td>0.673049</td>\n",
       "      <td>0.754720</td>\n",
       "      <td>0.747830</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18183</th>\n",
       "      <td>0.583741</td>\n",
       "      <td>0.826356</td>\n",
       "      <td>0.623551</td>\n",
       "      <td>0.972748</td>\n",
       "      <td>0.562227</td>\n",
       "      <td>0.764030</td>\n",
       "      <td>0.555396</td>\n",
       "      <td>0.675248</td>\n",
       "      <td>0.702103</td>\n",
       "      <td>0.751874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18184</th>\n",
       "      <td>0.600784</td>\n",
       "      <td>0.835548</td>\n",
       "      <td>0.624956</td>\n",
       "      <td>0.973858</td>\n",
       "      <td>0.570767</td>\n",
       "      <td>0.775102</td>\n",
       "      <td>0.552662</td>\n",
       "      <td>0.665891</td>\n",
       "      <td>0.743051</td>\n",
       "      <td>0.758528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18185 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "0      0.444368         0.503404         0.775435      0.744658    0.424873   \n",
       "1      0.281293         0.407681         0.622653      0.750489    0.273892   \n",
       "2      0.298531         0.416421         0.630442      0.756341    0.284520   \n",
       "3      0.300979         0.420463         0.629049      0.764024    0.286791   \n",
       "4      0.361704         0.464626         0.682901      0.775033    0.345385   \n",
       "...         ...              ...              ...           ...         ...   \n",
       "18180  0.573262         0.811219         0.618156      0.971489    0.545785   \n",
       "18181  0.742899         0.925674         0.704314      0.971683    0.709121   \n",
       "18182  0.623408         0.844800         0.640916      0.972058    0.593296   \n",
       "18183  0.583741         0.826356         0.623551      0.972748    0.562227   \n",
       "18184  0.600784         0.835548         0.624956      0.973858    0.570767   \n",
       "\n",
       "       EquivDiameter    Extent  Perimeter  Roundness  AspectRation  Class  \n",
       "0           0.666610  0.741661   0.537029   0.844997      0.368316      1  \n",
       "1           0.530370  0.804230   0.409661   0.919215      0.371471      1  \n",
       "2           0.546380  0.856278   0.412994   0.959862      0.374747      1  \n",
       "3           0.548616  0.883772   0.414262   0.961818      0.379222      1  \n",
       "4           0.601418  0.867808   0.452954   0.966836      0.386007      1  \n",
       "...              ...       ...        ...        ...           ...    ...  \n",
       "18180       0.757140  0.562384   0.654774   0.733291      0.744543      0  \n",
       "18181       0.861916  0.730296   0.758107   0.708884      0.745661      0  \n",
       "18182       0.789562  0.633098   0.673049   0.754720      0.747830      0  \n",
       "18183       0.764030  0.555396   0.675248   0.702103      0.751874      0  \n",
       "18184       0.775102  0.552662   0.665891   0.743051      0.758528      0  \n",
       "\n",
       "[18185 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalization of the data\n",
    "for col in data_df.columns:\n",
    "    if col != 'Class':\n",
    "        data_df[col] = (data_df[col])/ (data_df[col].max()) \n",
    "        \n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbbda9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data_df.iloc[:,:-1])\n",
    "y=np.array(data_df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85824182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18185, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6857ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18185,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa8a1c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d5ac91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "18180    0\n",
      "18181    0\n",
      "18182    0\n",
      "18183    0\n",
      "18184    0\n",
      "Name: Class, Length: 18185, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bdb6d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "y = np.array(data_df.iloc[:, -1]).reshape(-1, 1)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "903e5197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18185, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3818f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73b81bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12729, 10)\n",
      "(2728, 10)\n",
      "(2728, 10)\n"
     ]
    }
   ],
   "source": [
    "X_test,X_val,y_test,y_val=train_test_split(X_test,y_test,test_size=0.5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a236d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to convert our data into pytorch data set object\n",
    "#Converts raw data into a PyTorch Dataset object for efficient processing.\n",
    "class RiceDataset(Dataset):\n",
    "    def __init__(self,X, y):\n",
    "        self.X = torch.tensor(X,dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4f990c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = RiceDataset(X_train, y_train)\n",
    "validation_data = RiceDataset(X_val,y_val)\n",
    "test_data = RiceDataset(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54d2019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 10\n",
    "HIDDEN_NEURONS = 10\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "753685db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader=DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader=DataLoader(test_data, batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16852f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7a2feed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7516, 0.7850, 0.8305, 0.9093, 0.7093, 0.8670, 0.8901, 0.6818, 0.8868,\n",
      "         0.5363],\n",
      "        [0.8454, 0.8292, 0.8891, 0.9057, 0.8006, 0.9195, 0.8541, 0.7236, 0.8856,\n",
      "         0.5292],\n",
      "        [0.5963, 0.8137, 0.6413, 0.9669, 0.5720, 0.7722, 0.6416, 0.6604, 0.7497,\n",
      "         0.7198],\n",
      "        [0.6211, 0.8097, 0.6687, 0.9601, 0.5900, 0.7881, 0.6142, 0.6647, 0.7709,\n",
      "         0.6870],\n",
      "        [0.7874, 0.8185, 0.8385, 0.9176, 0.7498, 0.8873, 0.8963, 0.7074, 0.8629,\n",
      "         0.5538],\n",
      "        [0.5986, 0.8256, 0.6410, 0.9690, 0.5701, 0.7737, 0.5238, 0.6711, 0.7289,\n",
      "         0.7307],\n",
      "        [0.5770, 0.8566, 0.5944, 0.9825, 0.5541, 0.7596, 0.7098, 0.6826, 0.6792,\n",
      "         0.8176],\n",
      "        [0.6278, 0.8777, 0.6218, 0.9803, 0.5943, 0.7923, 0.5852, 0.6917, 0.7196,\n",
      "         0.8008]])\n",
      "====================\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dataloader:\n",
    "    print(x)\n",
    "    print(\"====================\")\n",
    "    print(y)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8036f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Architecture\n",
    "#The neural network structure and data flow.\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(X.shape[1], HIDDEN_NEURONS)\n",
    "        self.linear = nn.Linear(HIDDEN_NEURONS, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce7d8027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 10]             110\n",
      "            Linear-2                    [-1, 1]              11\n",
      "           Sigmoid-3                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MyModel().to(device)\n",
    "summary(model, (X.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38397050",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()                     # Measures how wrong predictions are (0 = perfect)\n",
    "optimizer = Adam(model.parameters(), lr=LR)  # Updates weights to make predictions better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0577d959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCELoss()\n"
     ]
    }
   ],
   "source": [
    "print(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00a16b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All tensor involved in computation must be on the same device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05058e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     23\u001b[39m labels= labels.to(device)\n\u001b[32m     25\u001b[39m prediction = model(inputs).squeeze(\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m batch_loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m total_loss_train += batch_loss.item()\n\u001b[32m     31\u001b[39m acc = ((prediction).round() == labels).sum().item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/loss.py:697\u001b[39m, in \u001b[36mBCELoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m    696\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m697\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/functional.py:3545\u001b[39m, in \u001b[36mbinary_cross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, reduce, reduction)\u001b[39m\n\u001b[32m   3543\u001b[39m     reduction_enum = _Reduction.get_enum(reduction)\n\u001b[32m   3544\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target.size() != \u001b[38;5;28minput\u001b[39m.size():\n\u001b[32m-> \u001b[39m\u001b[32m3545\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3546\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget.size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) is deprecated. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3547\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure they have the same size.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3548\u001b[39m     )\n\u001b[32m   3550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3551\u001b[39m     new_size = _infer_size(target.size(), weight.size())\n",
      "\u001b[31mValueError\u001b[39m: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "# Prepare the model\n",
    "# Feed data to the model\n",
    "# Calculate how wrong it is (loss)\n",
    "# Improve the model (backprop + optimizer)\n",
    "# Evaluate without training (validation)\n",
    "\n",
    "\n",
    "total_loss_train_plot = []\n",
    "total_loss_validation_plot = []\n",
    "total_acc_train_plot = []\n",
    "total_acc_validation_plot = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "    total_acc_val = 0\n",
    "    total_loss_val = 0\n",
    "    ## Training and Validation\n",
    "    for data in train_dataloader:\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels= labels.to(device)\n",
    "\n",
    "        prediction = model(inputs).squeeze(1)\n",
    "\n",
    "        batch_loss = criterion(prediction, labels)\n",
    "\n",
    "        total_loss_train += batch_loss.item()\n",
    "\n",
    "        acc = ((prediction).round() == labels).sum().item()\n",
    "\n",
    "        total_acc_train += acc\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    ## Validation\n",
    "    with torch.no_grad():\n",
    "        for data in validation_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            prediction = model(inputs).squeeze(1)\n",
    "\n",
    "            batch_loss = criterion(prediction, labels..squeeze(1))\n",
    "\n",
    "\n",
    "            total_loss_val += batch_loss.item()\n",
    "\n",
    "            acc = ((prediction).round() == labels).sum().item()\n",
    "\n",
    "            total_acc_val += acc\n",
    "\n",
    "    total_loss_train_plot.append(round(total_loss_train/1000, 4))\n",
    "    total_loss_validation_plot.append(round(total_loss_val/1000, 4))\n",
    "    total_acc_train_plot.append(round(total_acc_train/(training_data.__len__())*100, 4))\n",
    "    total_acc_validation_plot.append(round(total_acc_val/(validation_data.__len__())*100, 4))\n",
    "\n",
    "    print(f'''Epoch no. {epoch + 1} Train Loss: {total_loss_train/1000:.4f} Train Accuracy: {(total_acc_train/(training_data.__len__())*100):.4f} Validation Loss: {total_loss_val/1000:.4f} Validation Accuracy: {(total_acc_val/(validation_data.__len__())*100):.4f}''')\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f39923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7272f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a730d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
